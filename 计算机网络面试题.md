# 计算机网络面试题

## 1. OSI七层模型分别是什么？各自的功能是什么？

- 物理层：实现的是底层的数据传输，通过物理介质传送比特流。使得上层不必关心是通过什么介质传输的。
- 数据链路层：定义数据的基本格式，将比特组合成字节，再将字节组合成帧。使用链路层地址（MAC）来访问介质，并进行差错检测
- 网络层：通过IP寻址来建立两个结点之间的连接，为传输层的分组选择合适的路由和交换结点。主要的协议是IP协议。
- 传输层：建立了主机端到端的链接，传输层的作用是为上层协议提供端到端的可靠和透明的数据传输服务，包括处理差错控制和流量控制等问题。主要的协议有TCP/UDP协议。
- 会话层：负责建立、管理和终止表示层实体之间的通信会话。
- 表示层：提供各种用于应用层数据的编码和转换功能，确保一个系统的应用层发送的数据能被另一个系统的应用层识别。例如数据的压缩与解压缩，加密与解密等。
- 应用层：为计算机用户提供应用接口，也为用户直接提供各种网络服务。比如说HTTP、SMTP、FTP等是应用层的协议。

[OSI七层模型详细讲解点击这](https://www.cnblogs.com/sunweiye/p/11083601.html)

## 2. TCP和UDP的区别？各自有什么应用场景？

- TCP提供可靠的传输，UDP不提供可靠的传输，它会尽最大努力提供交付。
- TCP是面向连接的，UDP是无连接的。
- TCP传输数据具有有序性，而UDP不保证数据的有序。
- TCP的传输速度相对于UDP较慢。
- TCP有流量控制和拥塞控制，UDP则没有。
- TCP是重量级协议，UDP是轻量级协议。
- TCP连接只能有两个端点，即TCP是端到端的。而UDP可以是一对一，一对多，多对多的。
- TCP是面向字节流传输的，不保存数据的边界。UDP则是面向报文传输的，保存数据的边界。



- TCP的应用场景应是效率需求低，但是对准确性要求高。比如说文件的传输，邮件的传输，支付等。
- UDP的应用场景则是对效率要求高，对准确性要求不高。比如说即时通讯，在线视频等。

## 3. 为什么要三次握手？两次不行吗？

- 第一次握手：客户端给服务端发送一个SYN报文，指明客户端初始化序列号ISN，此时客户端处于 **SYN_SENT** 状态。服务端收到了，那么服务端就可以确定**客户端的发送能力**是正常的。
- 第二次握手：服务端收到了，给客户端发送一个自己的SYN报文作为应答，并指明自己的初始化序列号，同时把客户端的 ISN + 1 作为 ACK 的值，表示自己收到了客户端的 SYN，此时服务端处于 **SYN_RCVD** 状态。客户端收到了，就可以确定**服务端的发送能力**和**接收能力**是正常的，但是服务端还不能确定客户端的接收能力是否正常。
- 第三次握手：客户端收到 SYN 报文后，向服务端发送 ACK 报文，也是将服务端的 ISN + 1 作为 ACK 的值。表示已经收到服务端的 SYN 报文。服务端收到了，就可以确定**客户端的接收能力**是正常的，此时双方都处于 **established** 状态。

综上所述，只有三次握手双方才能确定对方的发送能力和接收能力是正常的。

ps：第三次握手是可以携带数据发送的，因为客户端此时已经可以确定服务端的发送能力和接收能力是正常的了。

![三次握手](https://img-blog.csdnimg.cn/2020082716294932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80ODY4NDI3NA==,size_16,color_FFFFFF,t_70#pic_center)

## 4. 为什么要四次挥手？三次不行吗？

- 第一次挥手：客户端发起断开连接请求，向服务端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 **FIN_WAIT1** 状态。
- 第二次挥手：服务端收到客户端发送的 FIN 报文后，会发送一个 ACK 报文，把客户端的序列号 + 1 作为其值。表示收到客户端的报文了，此时，服务端处于 **CLOSE_WAIT** 状态。
- 第三次挥手：如果服务端也想关闭连接了，也会向客户端发送一个 FIN 报文，且指定一个序列号。此时服务端处于 **LAST_ACK** 状态。
- 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 **TIME_WAIT** 状态。**需要过一阵子**以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态。

为什么要等一阵子（2MSL）客户端才进入 CLOSED 状态呢？因为它要确保服务端收到了自己的 ACK 报文，如果服务端没收到，会重新发送一个 FIN 报文请求断开连接。

![四次挥手](https://img2018.cnblogs.com/blog/1535576/201910/1535576-20191012001944770-1619591507.png)

## 5. HTTP 和 HTTPS 的区别？

HTTPS 协议一般理解为 HTTP+SSL/TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。

HTTPS 在应用层和传输层之间又建立了一个安全层，在这个安全通道中进行数据的传输。在传输过程中，会对数据进行加密处理。保证数据的完整性，保密性。并且浏览器还会对服务器进行一个源端鉴别，确保目标地址的安全性。

HTTPS的端口是443，而HTTP的端口是80。

HTTPS也有缺点，其多次握手，导致页面的加载时间延长近50%；HTTPS的连接缓存不如HTTP高效，会增加数据的开销与消耗。且向CA申请证书需要钱，功能越强，花费越大。



>HTTPS 采用混合加密机制，即非对称加密（公开秘钥加密，公钥加密，私钥解密）和对称加密（共享秘钥加密，私钥加密解密）一起使用。在交换秘钥环节，客户端向服务端发送用**公开秘钥的公钥加密**的**共享秘钥的私钥**，服务端收到之后，用公开密钥加密的私钥解密，得到**共享秘钥的私钥**。之后，双方就可以用共享秘钥加解密来进行通信了。

## 6. TCP 协议是如何保证数据可靠传输的？

- 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据。
- 对失序数据包重排序：TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层。
- 丢弃重复数据：对于重复数据，能够丢弃重复数据。
- 应答机制：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒。
- 超时重发：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。
- 流量控制：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的滑动窗口协议。

## 7. 谈谈你对滑动窗口的理解

TCP 通过滑动窗口机制实现流量控制，早期的网络通信过程中，由于没有对网络通信的拥挤情况进行控制，通信双方不知道网络拥塞情况。当网络发生拥塞时，还在传输数据，就会发生丢包现象。所以就有了滑动窗口来解决拥塞问题。

TCP 通过滑动窗口来实现传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用来接收数据，发送方可以根据滑动窗口的大小来确定可以发送多少字节的数据。如果接收方的滑动窗口大小为0，发送方就不能再发送数据了。这样就可以有效避免发生网络拥塞问题。

## 8. 谈谈你对 TCP 拥塞控制的理解？用到了什么算法？

拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不至于过载。拥塞控制所要做的都有一个前提，就是网络能够承载现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。

而流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做的就是抑制发送端发送数据的速率，一遍接收端来得及接收。

为了进行拥塞控制，TCP 发送方需要维持一个拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且是动态变化的。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口的最小值。

TCP 拥塞控制采用了四种算法。即：慢开始、拥塞避免、快重传和快恢复。

- **慢开始**：慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据注入网络中，那么就可能会引起网络阻塞，因为现在还不知道网络的负荷情况。所以最好的办法是先探测一下，然后再逐步增大发送窗口。
- **拥塞避免**：拥塞避免的思路是让拥塞窗口缓慢增大，每经过一个往返时间 RTT 就把发送方的拥塞窗口 + 1。
- **快重传**：在 TCP 传输过程中，如果发生了丢包，接收端就会重复发送之前的 ACK。比如第5个包丢了，6，7到达了。那么接收端会为5,6,7都发送第4个包的ACK，这个时候发送端收到了3个相同的 ACK ，就会意识到丢包了，就会马上进行重传，而不用等到 RTO（超时重传时间）。
- **快恢复**：如果发送端收到了3个重复的 ACK，发生了丢包，觉得现在的网络状况已经进入了拥塞状态了，那么就会进入快速恢复阶段。
  - 会将拥塞阈值降低为拥塞窗口的一半
  - 拥塞窗口的大小变为拥塞阈值
  - 然后拥塞窗口在线性增加，来适应网络情况。

## 9. UDP 如何实现可靠传输？

- 添加 seq / ack 机制，确保数据发送到了接收端

- 添加发送和接收缓冲区，用于超时重传。

  ps：需要在应用层实现

## 10. HTTP/1.0，HTTP/1.1，HTTP/2.0 有什么区别？

- **HTTP/1.0**：其规定浏览器和服务器之间只能保持短暂的连接，浏览器每次请求都需要与服务器建立一个TCP连接，服务器完成请求后立即断开连接。而每次建立连接都需要三次挥手，比较耗费时间，所以 HTTP/1.0 的性能很差。
- **HTTP/1.1**：最主要的改进就是引入了持久连接。即 TCP 连接默认不关闭，可以被多个请求复用。但是服务端还是按顺序执行。
- **HTTP/2.0**：其采用了多路复用，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应。可以这样做的原因是：HTTP/2.0 进行了二进制分帧，即 HTTP/2.0 会将所有传输的信息分割为更小的消息和帧，并对他们进行二进制格式的编码。除此之外，还对 header 进行了压缩，使性能进一步提升。

## 11. DNS 解析过程

主机向本地域名服务器的查询一般都是采用**递归查询**。如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。

本地域名服务器向根域名服务器的查询的迭代查询。当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。**根域名服务器**通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。**顶级域名服务器**在收到本地域名服务器的查询请求后，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应当向哪一个**权限域名服务器**进行查询。

## 12. 在浏览器中输入 URL 地址到显示主页的过程？

- DNS 解析
- TCP 连接 三次握手
- 发送 HTTP 请求
- 服务器处理请求并返回 HTTP 报文
- 浏览器渲染解析界面
- 断开连接 四次挥手